{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.onmf import Online_NMF, update_code_within_radius\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.transform import downscale_local_mean\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "from tensorly import unfold as tl_unfold\n",
    "from tqdm import trange\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n"
     ]
    }
   ],
   "source": [
    "class Image_Reconstructor():\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 n_components=100,\n",
    "                 iterations=200,\n",
    "                 sub_iterations=20,\n",
    "                 num_patches=1000,\n",
    "                 batch_size=20,\n",
    "                 downscale_factor=2,\n",
    "                 patch_size=7,\n",
    "                 patches_file='',\n",
    "                 patches = None,\n",
    "                 is_matrix=False,\n",
    "                 is_stack=False,\n",
    "                 is_color=True):\n",
    "        '''\n",
    "        batch_size = number of patches used for training dictionaries per ONMF iteration\n",
    "        sources: array of filenames to make patches out of\n",
    "        patches_array_filename: numpy array file which contains already read-in images\n",
    "        '''\n",
    "        self.path = path\n",
    "        self.n_components = n_components\n",
    "        self.iterations = iterations\n",
    "        self.sub_iterations = sub_iterations\n",
    "        self.num_patches = num_patches\n",
    "        self.batch_size = batch_size\n",
    "        self.downscale_factor = downscale_factor\n",
    "        self.patch_size = patch_size\n",
    "        self.patches = patches\n",
    "        self.patches_file = patches_file\n",
    "        self.is_matrix = is_matrix\n",
    "        self.is_stack = is_stack  # if True, input data is a 3d array\n",
    "        self.is_color = is_color\n",
    "        self.W = np.zeros(shape=(patch_size**2, n_components))\n",
    "        if is_color:\n",
    "            #self.W = np.ones(shape=(3*patch_size**2, n_components))\n",
    "            self.W = np.random.rand(3*patch_size**2, n_components)\n",
    "        self.code = np.ones(shape=(n_components, iterations*batch_size))\n",
    "        self.A_recons = []\n",
    "\n",
    "        '''\n",
    "        # read in patches\n",
    "        if patches_file:\n",
    "            self.patches = np.load(patches_file)\n",
    "        elif not is_stack:\n",
    "            self.patches = self.read_patches(patch_size=patch_size, iterations=iterations,\n",
    "                                             batch_size=batch_size, is_matrix=is_matrix)\n",
    "            print(self.patches.shape)\n",
    "        else:\n",
    "            self.patches = self.read_patches_stack(patch_size=patch_size, iterations=iterations,\n",
    "                                                   batch_size=batch_size)\n",
    "            b = np.asarray(self.patches)\n",
    "            b = np.moveaxis(b, 0, -1)\n",
    "            self.patches = b\n",
    "            print(self.patches.shape)\n",
    "        '''\n",
    "        # read in image as array\n",
    "        self.data = self.read_img_as_array(path=self.path, is_matrix=self.is_matrix, is_color=self.is_color)\n",
    "\n",
    "    def read_img_as_array(self, path, is_matrix=False, is_color=True):\n",
    "        '''\n",
    "        Read input image as a narray\n",
    "        '''\n",
    "\n",
    "        if is_matrix:\n",
    "            img = np.load(path)\n",
    "            data = (img + 1) / 2  # it was +-1 matrix; now it is 0-1 matrix\n",
    "        else:\n",
    "            img = Image.open(path)\n",
    "            if is_color:\n",
    "                img = img.convert('RGB')\n",
    "                #  = data.reshape(-1, data.shape[1])  # (row, col, 3) --> (3row, col)\n",
    "            else:\n",
    "                img = img.convert('L')\n",
    "            data = np.asarray(img) / 255\n",
    "            print('img.shape', data.shape)\n",
    "            # normalize pixel values (range 0-1)\n",
    "        print('data.shape', data.shape)\n",
    "        return data\n",
    "\n",
    "    def read_patches(self, patch_size=7, iterations=500, batch_size=20, is_matrix=False):\n",
    "        '''\n",
    "        reads in patches from images specified by self.sources\n",
    "        '''\n",
    "        patches = []\n",
    "        for filename in self.sources:\n",
    "            print(\"reading {}\".format(filename))\n",
    "            img_patches = self.image_to_patches(filename, iterations=iterations, batch_size=batch_size,\n",
    "                                                patch_size=patch_size, is_matrix=is_matrix)\n",
    "            patches = patches + img_patches.T.tolist()\n",
    "        return np.array(patches).T\n",
    "\n",
    "    def read_patches_stack(self, patch_size=7, iterations=500, batch_size=20):\n",
    "        '''\n",
    "        reads in patches from stack of matrices specified by self.sources\n",
    "        '''\n",
    "        stack_patches = []\n",
    "        for filename in self.sources:\n",
    "            print(\"reading {}\".format(filename))\n",
    "            stack_patches = self.stack_to_patches(filename, patch_size=patch_size, iterations=iterations,\n",
    "                                                  batch_size=batch_size)\n",
    "        return np.array(stack_patches)\n",
    "\n",
    "    def image_to_patches(self, path, patch_size=7, iterations=500, batch_size=20, color=False, downscale_factor=2,\n",
    "                         is_matrix=False, is_recons=False):\n",
    "        '''\n",
    "        #*****\n",
    "\n",
    "        args:\n",
    "            path (string): Path and filename of input image\n",
    "            patch_size (int): Pixel dimension of square patches taken of image\n",
    "            color (boolean): Specifies conversion of image to RGB (True) or grayscale (False).\n",
    "                Default value = false. When color = True, images in gray colorspace will still appear\n",
    "                gray, but will thereafter be represented in RGB colorspace using three channels.\n",
    "            downscale_factor: Specifies the extent to which the image will be downscaled. Greater values\n",
    "                will result in more downscaling but faster speed. For no downscaling, use downscale_factor=1.\n",
    "        returns: #***\n",
    "\n",
    "        '''\n",
    "        #open image and convert it to either RGB (three channel) or grayscale (one channel)\n",
    "        if is_matrix:\n",
    "            img = np.load(path)\n",
    "            data = (img + 1) / 2  # it was +-1 matrix; now it is 0-1 matrix\n",
    "        else:\n",
    "            img = Image.open(path)\n",
    "            if color:\n",
    "                img = img.convert('RGB')\n",
    "                img = tl_unfold(img, mode=2).T\n",
    "                print('img.shape_color_after_unfolding', img.shape)\n",
    "            else:\n",
    "                img = img.convert('L')\n",
    "            # normalize pixel values (range 0-1)\n",
    "            data = np.asarray(img) / 255\n",
    "\n",
    "        '''\n",
    "        img = np.load(path)\n",
    "        data = (img + 1) / 2  # it was +-1 matrix; now it is 0-1 matrix\n",
    "        '''\n",
    "        if DEBUG:\n",
    "            print(np.asarray(img))\n",
    "\n",
    "        # downscale image for speed\n",
    "        if downscale_factor > 1:\n",
    "            data = downscale_local_mean(data, (downscale_factor, downscale_factor))\n",
    "\n",
    "        # show_array(data)\n",
    "        if not is_recons:\n",
    "            patches = extract_patches_2d(data, (patch_size, patch_size), max_patches=iterations*batch_size)\n",
    "        else:  # for reconstruction we need to use all patches not to mess up with the ordering\n",
    "            patches = extract_patches_2d(data, (patch_size, patch_size))\n",
    "        # we do not need more than iterations*batch_size patches for training dictionaries\n",
    "        # convert 7x7 squares to 1d (49,) vectors\n",
    "        patches_flat = patches.reshape(len(patches), -1).T\n",
    "        # (Num patches)*(7*7) array\n",
    "        # .reshape(len(patches),-1) makes it two dimensional -- (Num patches)*(whatever that's correct)\n",
    "        # take transpose to make it 49 * (Num patches)\n",
    "        print(patches_flat.shape)\n",
    "        return patches_flat\n",
    "\n",
    "    def extract_random_patches(self):\n",
    "        '''\n",
    "        Extract 'num_patches' many random patches of given size\n",
    "        color -- 3 patch_size * patch_size (color pixels are flattened)\n",
    "        b/w -- patch_size * patch_size\n",
    "        '''\n",
    "        x = self.data.shape\n",
    "        k = self.patch_size\n",
    "\n",
    "        if self.is_color:\n",
    "            X = np.zeros(shape=(3*(k ** 2), 1))\n",
    "            for i in np.arange(self.num_patches):\n",
    "                a = np.random.choice(x[0] - k)  # y coordinate of the top left corner of the random patch\n",
    "                b = np.random.choice(x[1] - k)  # x coordinate of the top left corner of the random patch\n",
    "                Y = self.data[a:a+k, b:b+k, :]\n",
    "                Y = Y.reshape((-1, 1))  # size 3k**2 by 1\n",
    "                # print('Y.shape', Y.shape)\n",
    "                if i == 0:\n",
    "                    X = Y\n",
    "                else:\n",
    "                    X = np.append(X, Y, axis=1)  # x is class ndarray\n",
    "        else:  # b/w image\n",
    "            X = np.zeros(shape=(k ** 2, 1, 1))\n",
    "            for i in np.arange(self.num_patches):\n",
    "                a = np.random.choice(x[0] - k)  # x coordinate of the top left corner of the random patch\n",
    "                b = np.random.choice(x[1] - k)  # y coordinate of the top left corner of the random patch\n",
    "                Y = self.data[a:a + k, b:b + k]\n",
    "                Y = Y.reshape(k ** 2, 1)  # size k**2 by 1\n",
    "                # print('Y.shape', Y.shape)\n",
    "                if i == 0:\n",
    "                    X = Y\n",
    "                else:\n",
    "                    X = np.append(X, Y, axis=1)  # X is class ndarray\n",
    "        return X  # X.shape = (3k**2, num_patches) for color, (k**2, 1) for b/w\n",
    "\n",
    "    def stack_to_patches(self, path, patch_size=7, iterations=500, batch_size=20, downscale_factor=2):\n",
    "        # converts a stack of data matrices into 3d array of patch matrices\n",
    "        X = np.load(path)\n",
    "        data = (X + 1) / 2\n",
    "        m = X.shape[0]  # number of matrices stacked up\n",
    "        stack_patches_flat = []\n",
    "        for i in np.arange(0, m):\n",
    "            img = data[i, :, :]\n",
    "            # downscale image for speed\n",
    "            if downscale_factor > 1:\n",
    "                img = downscale_local_mean(img, (downscale_factor, downscale_factor))\n",
    "\n",
    "            # show_array(data)\n",
    "            patches = extract_patches_2d(img, (patch_size, patch_size), max_patches=iterations * batch_size)\n",
    "            # we do not need more than iterations*batch_size patches for training dictionaries\n",
    "            patches_flat = patches.reshape(len(patches), -1).T  # -1 means unspecified\n",
    "            stack_patches_flat.append(patches_flat)\n",
    "\n",
    "        #  b = np.asarray(stack_patches_flat)\n",
    "        #  np.moveaxis(b, 0, -1)\n",
    "        #  stack_patches_flat = np.stack((stack_patches_flat, patches_flat), axis=0)\n",
    "        return stack_patches_flat\n",
    "\n",
    "    def save_patches(self, filename):\n",
    "        '''\n",
    "        Save patches array to filename. in future set patches_file in constructor\n",
    "        '''\n",
    "        np.save(filename, self.patches)\n",
    "\n",
    "    def display_dictionary(self, W):\n",
    "        k = self.patch_size\n",
    "        \n",
    "        rows = np.round(np.sqrt(W.shape[1]))\n",
    "        rows = rows.astype(int)\n",
    "        if rows ** 2 == W.shape[1]:\n",
    "            cols = rows\n",
    "        else:\n",
    "            cols = rows + 1\n",
    "        \n",
    "        fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(6,6),\n",
    "                                subplot_kw={'xticks':[], 'yticks': []})\n",
    "        \n",
    "        for ax, i in zip(axs.flat, range(rows*cols)):\n",
    "            if not self.is_color:\n",
    "                ax.imshow(W.T[i].reshape(k, k), cmap=\"gray\", interpolation='nearest')\n",
    "            else:\n",
    "                patch = W.T[i].reshape(k, k, 3)\n",
    "                ax.imshow(patch/np.max(patch))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Dictionary learned from patches of size %d' % k, fontsize=16)\n",
    "        plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "        plt.show()\n",
    "            \n",
    "\n",
    "    def get_downscaled_dims(self, path, downscale_factor=None, is_matrix=False):\n",
    "        # need to put is_matrix arg at the end to avoid error (don't know why)\n",
    "        if downscale_factor is None:\n",
    "            downscale_factor = self.downscale_factor\n",
    "\n",
    "        if not is_matrix:\n",
    "            img = Image.open(path)\n",
    "            img = np.asarray(img.convert('L'))\n",
    "        else:\n",
    "            img = np.load(path)\n",
    "\n",
    "        data = downscale_local_mean(img, (downscale_factor, downscale_factor))\n",
    "        return data.shape[0], data.shape[1]\n",
    "\n",
    "    def train_dict(self, is_stack=False):\n",
    "        print('training dictionaries from patches...')\n",
    "        '''\n",
    "        Trains dictionary based on patches.\n",
    "        '''\n",
    "        W = self.W\n",
    "        At = []\n",
    "        Bt = []\n",
    "        code = self.code\n",
    "        for t in trange(self.iterations):\n",
    "            X = self.extract_random_patches()\n",
    "            if t == 0:\n",
    "                self.onmf = Online_NMF(data,\n",
    "                                  n_components=self.n_components,\n",
    "                                  iterations=self.sub_iterations,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  ini_dict=None,\n",
    "                                  ini_agg=None,\n",
    "                                  history=0,\n",
    "                                  alpha=None)\n",
    "                W, aggregates, H = onmf.train_dict()\n",
    "               \n",
    "            else:\n",
    "                self.onmf = Online_NMF(data,\n",
    "                                  n_components=self.n_components,\n",
    "                                  iterations=self.sub_iterations,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  ini_dict=W,\n",
    "                                  ini_agg = aggregates,\n",
    "                                  beta=forgetting_param,\n",
    "                                  history=onmf.history,\n",
    "                                  alpha=None)\n",
    "                W, aggregates, H = onmf.train_dict()\n",
    "            \n",
    "        self.W = W\n",
    "        print('dict_shape:', self.W.shape)\n",
    "        print('code_shape:', self.code.shape)\n",
    "\n",
    "    def show_array(self, arr):\n",
    "        plt.figure()\n",
    "        plt.imshow(arr, cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "    def reconstruct_image(self, path, downscale_factor=None, patch_size=10, is_matrix=False):\n",
    "        print('reconstructing given image...')\n",
    "        if downscale_factor is None:\n",
    "            downscale_factor = self.downscale_factor\n",
    "\n",
    "        t0 = time()\n",
    "        dims = self.get_downscaled_dims(path, downscale_factor, is_matrix=is_matrix)\n",
    "        patches = self.image_to_patches(path, patch_size=patch_size, downscale_factor=downscale_factor,\n",
    "                                        is_matrix=is_matrix, is_recons=True)\n",
    "        self.nmf = Online_NMF(patches, self.n_components, self.iterations, self.batch_size)\n",
    "        code = self.nmf.sparse_code(patches, self.W)\n",
    "        print('Reconstructed in %.2f seconds' % (time() - t0))\n",
    "        patches_recons = np.dot(self.W, code).T\n",
    "        patches_recons = patches_recons.reshape(patches_recons.shape[0], patch_size, patch_size)\n",
    "        img_recons = reconstruct_from_patches_2d(patches_recons, (dims[0], dims[1]))\n",
    "        self.show_array(img_recons)\n",
    "        return code\n",
    "\n",
    "    def reconstruct_image_color(self, path, recons_resolution=1):\n",
    "        print('reconstructing given network...')\n",
    "        '''\n",
    "        Note: For WAN data, the algorithm reconstructs the normalized WAN matrix A/np.max(A).\n",
    "        Scale the reconstructed matrix B by np.max(A) and compare with the original network.\n",
    "        '''\n",
    "        A = self.read_img_as_array(path)  # A.shape = (row, col, 3)\n",
    "        A_matrix = A.reshape(-1, A.shape[1])  # (row, col, 3) --> (3row, col)\n",
    "        [m, n] = A_matrix.shape\n",
    "        A_recons = np.zeros(shape=A.shape)\n",
    "        A_overlap_count = np.zeros(shape=(A.shape[0], A.shape[1]))\n",
    "        k = self.patch_size\n",
    "        t0 = time()\n",
    "        c = 0\n",
    "        num_rows = np.floor((A_recons.shape[0]-k)/recons_resolution).astype(int)\n",
    "        num_cols = np.floor((A_recons.shape[1]-k)/recons_resolution).astype(int)\n",
    "\n",
    "        for i in trange(0, A_recons.shape[0]-k, recons_resolution):\n",
    "            for j in np.arange(0, A_recons.shape[1]-k, recons_resolution):\n",
    "                patch = A[i:i + k, j:j + k, :] # k by k by 3\n",
    "                patch = patch.reshape((-1, 1))  # make the patch as a column vector\n",
    "                # print('patch.shape', patch.shape)\n",
    "                # coder = SparseCoder(dictionary=self.W.T, transform_n_nonzero_coefs=None,\n",
    "                #                    transform_alpha=1, transform_algorithm='lasso_lars', positive_code=True)\n",
    "                # alpha = L1 regularization parameter. alpha=2 makes all codes zero (why?)\n",
    "                # code = coder.transform(patch.T)\n",
    "                code = update_code_within_radius(patch, self.W, H0=None, r=None, alpha=1, sub_iter=10, stopping_diff=0.01)\n",
    "                patch_recons = np.dot(self.W, code).T\n",
    "                patch_recons = patch_recons.reshape(k, k, 3)\n",
    "\n",
    "                # now paint the reconstruction canvas\n",
    "                for x in itertools.product(np.arange(k), repeat=2):\n",
    "                    c = A_overlap_count[i+x[0], j+x[1]]\n",
    "                    A_recons[i+x[0], j+x[1], :] = (c*A_recons[i+x[0], j+x[1], :] + patch_recons[x[0], x[1], :])/(c+1)\n",
    "                    A_overlap_count[i+x[0], j+x[1]] += 1\n",
    "\n",
    "                # progress status\n",
    "                #print('reconstructing (%i, %i)th patch out of (%i, %i)' % (i/recons_resolution, j/recons_resolution, num_rows, num_cols))\n",
    "        print('Reconstructed in %.2f seconds' % (time() - t0))\n",
    "        print('A_recons.shape', A_recons.shape)\n",
    "        np.save('Image_dictionary/img_recons_color', A_recons)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6,6),\n",
    "                                subplot_kw={'xticks':[], 'yticks': []})\n",
    "        ax.imshow(A_recons)\n",
    "        plt.suptitle('Reconstructed image')\n",
    "        plt.savefig('Image_dictionary/img_recons_color1.jpg', bbox_inches='tight')\n",
    "        self.A_recons = A_recons\n",
    "        return A_recons\n",
    "    \n",
    "    \n",
    "def display_recons_dict_list(W_list, \n",
    "                                 training_iter_list,\n",
    "                                 A_recons_list,\n",
    "                                 save_path,\n",
    "                                 title=None,\n",
    "                                 grid_shape=None,\n",
    "                                 fig_size=[10,10]):\n",
    "        W = W_list[0]\n",
    "        n_components = W.shape[1]\n",
    "        print('W.shape', W.shape)\n",
    "        k = int(np.sqrt(W.shape[0]/3))\n",
    "\n",
    "        rows = np.round(np.sqrt(n_components))\n",
    "        rows = rows.astype(int)\n",
    "        if grid_shape is not None:\n",
    "            rows = grid_shape[0]\n",
    "            cols = grid_shape[1]\n",
    "        else:\n",
    "            if rows ** 2 == n_components:\n",
    "                cols = rows\n",
    "            else:\n",
    "                cols = rows + 1\n",
    "\n",
    "        idx = np.arange(W.shape[1])\n",
    "\n",
    "        fig = plt.figure(figsize=fig_size, constrained_layout=False)\n",
    "        outer_grid = gridspec.GridSpec(nrows=2, ncols=len(W_list)+1, wspace=0.2, hspace=0.2)\n",
    "        for t in np.arange(3):\n",
    "            # make nested gridspecs\n",
    "\n",
    "            if t == 1: # dictionary\n",
    "                for j in np.arange(len(W_list)):\n",
    "                    W = W_list[j]\n",
    "                    ### Make gridspec\n",
    "                    inner_grid = outer_grid[t, j+1].subgridspec(rows, cols, wspace=0.2, hspace=0.02)\n",
    "                    #gs1 = fig.add_gridspec(nrows=rows, ncols=cols, wspace=0.05, hspace=0.05)\n",
    "\n",
    "                    for i in range(rows * cols):\n",
    "                        a = i // cols\n",
    "                        b = i % cols\n",
    "                        ax = fig.add_subplot(inner_grid[a, b])\n",
    "                        patch = W.T[idx[i]].reshape(k, k, 3)\n",
    "                        ax.imshow(patch/np.max(patch), interpolation='nearest')\n",
    "                        #ax.set_xlabel('Training iter = %i' % training_iter_list[j], fontsize=13)  # get the largest first\n",
    "                        # ax.xaxis.set_label_coords(0.5, -0.05)  # adjust location of importance appearing beneath patches\n",
    "                        ax.set_xticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        \n",
    "            if t == 0: # reconstruction\n",
    "                for j in np.arange(len(W_list)):\n",
    "                    A_recons = A_recons_list[j]\n",
    "\n",
    "                    inner_grid = outer_grid[t, j+1].subgridspec(1, 1, wspace=0, hspace=0)\n",
    "                    ax = fig.add_subplot(inner_grid[0, 0])\n",
    "                    ax.imshow(A_recons)\n",
    "                    \n",
    "            if t == 2: # original\n",
    "                a = 1\n",
    "                for j in np.arange(len(W_list), len(W_list)+2):\n",
    "                    A = A_recons_list[j]\n",
    "                    inner_grid = outer_grid[a, 0].subgridspec(1, 1, wspace=0, hspace=0)\n",
    "                    ax = fig.add_subplot(inner_grid[0, 0])\n",
    "                    ax.imshow(A)\n",
    "                    a -= 1\n",
    "                \n",
    "        if title is not None:\n",
    "            plt.suptitle(title, fontsize=25)\n",
    "        fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0)\n",
    "        fig.savefig(save_path, bbox_inches='tight')\n",
    "        \n",
    "def display_recons_dict_list(W_list, \n",
    "                                 training_iter_list,\n",
    "                                 A_recons_list,\n",
    "                                 save_path,\n",
    "                                 title=None,\n",
    "                                 grid_shape=None,\n",
    "                                 fig_size=[10,10]):\n",
    "        W = W_list[0]\n",
    "        n_components = W.shape[1]\n",
    "        print('W.shape', W.shape)\n",
    "        k = int(np.sqrt(W.shape[0]/3))\n",
    "\n",
    "        rows = np.round(np.sqrt(n_components))\n",
    "        rows = rows.astype(int)\n",
    "        if grid_shape is not None:\n",
    "            rows = grid_shape[0]\n",
    "            cols = grid_shape[1]\n",
    "        else:\n",
    "            if rows ** 2 == n_components:\n",
    "                cols = rows\n",
    "            else:\n",
    "                cols = rows + 1\n",
    "\n",
    "        idx = np.arange(W.shape[1])\n",
    "\n",
    "        fig = plt.figure(figsize=fig_size, constrained_layout=False)\n",
    "        outer_grid = gridspec.GridSpec(nrows=2, ncols=len(W_list)+1, wspace=0.2, hspace=0.2)\n",
    "        for t in np.arange(3):\n",
    "            # make nested gridspecs\n",
    "\n",
    "            if t == 1: # dictionary\n",
    "                for j in np.arange(len(W_list)):\n",
    "                    W = W_list[j]\n",
    "                    ### Make gridspec\n",
    "                    inner_grid = outer_grid[t, j+1].subgridspec(rows, cols, wspace=0.2, hspace=0.02)\n",
    "                    #gs1 = fig.add_gridspec(nrows=rows, ncols=cols, wspace=0.05, hspace=0.05)\n",
    "\n",
    "                    for i in range(rows * cols):\n",
    "                        a = i // cols\n",
    "                        b = i % cols\n",
    "                        ax = fig.add_subplot(inner_grid[a, b])\n",
    "                        patch = W.T[idx[i]].reshape(k, k, 3)\n",
    "                        ax.imshow(patch/np.max(patch), interpolation='nearest')\n",
    "                        #ax.set_xlabel('Training iter = %i' % training_iter_list[j], fontsize=13)  # get the largest first\n",
    "                        # ax.xaxis.set_label_coords(0.5, -0.05)  # adjust location of importance appearing beneath patches\n",
    "                        ax.set_xticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        \n",
    "            if t == 0: # reconstruction\n",
    "                for j in np.arange(len(W_list)):\n",
    "                    A_recons = A_recons_list[j]\n",
    "\n",
    "                    inner_grid = outer_grid[t, j+1].subgridspec(1, 1, wspace=0, hspace=0)\n",
    "                    ax = fig.add_subplot(inner_grid[0, 0])\n",
    "                    ax.imshow(A_recons)\n",
    "                    \n",
    "            if t == 2: # original\n",
    "                a = 1\n",
    "                for j in np.arange(len(W_list), len(W_list)+2):\n",
    "                    A = A_recons_list[j]\n",
    "                    inner_grid = outer_grid[a, 0].subgridspec(1, 1, wspace=0, hspace=0)\n",
    "                    ax = fig.add_subplot(inner_grid[0, 0])\n",
    "                    ax.imshow(A)\n",
    "                    a -= 1\n",
    "                \n",
    "        if title is not None:\n",
    "            plt.suptitle(title, fontsize=25)\n",
    "        fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0)\n",
    "        fig.savefig(save_path, bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    patch_size = 10\n",
    "    #sources = [\"Data/renoir/\" + str(n) + \".jpg\" for n in np.arange(0,1)]\n",
    "    path_dict_img = \"Data/piccaso/1.jpg\"\n",
    "    path_recons = \"Data/renoir/0.jpg\"\n",
    "    training_iter_list = [0,2,1000]\n",
    "    W_list = []\n",
    "    A_recons_list = []\n",
    "    for training_iter in training_iter_list:\n",
    "        reconstructor = Image_Reconstructor(path=path_dict_img,\n",
    "                                            n_components=25,\n",
    "                                            iterations=training_iter,\n",
    "                                            sub_iterations=10,\n",
    "                                            patch_size=patch_size,\n",
    "                                            batch_size=10,\n",
    "                                            num_patches=10,\n",
    "                                            downscale_factor=10,\n",
    "                                            is_matrix=False,\n",
    "                                            is_color=True)\n",
    "        # reconstructor.save_patches(\"escher_patches.npy\")\n",
    "        reconstructor.train_dict()\n",
    "        # reconstructor.W = np.load('Image_dictionary/dict_learned_21.npy')\n",
    "        W_list.append(reconstructor.W)  # trained dictionary\n",
    "        #reconstructor.display_dictionary(img_dict)\n",
    "        reconstructor.reconstruct_image_color(path=path_recons,\n",
    "                                              recons_resolution=10)\n",
    "        A_recons_list.append(reconstructor.A_recons)\n",
    "\n",
    "    ### Append original images for dictionary learning and reconstruction \n",
    "    img_dict = reconstructor.read_img_as_array(path_dict_img, is_matrix=False, is_color=True)\n",
    "    img_recons = reconstructor.read_img_as_array(path_recons, is_matrix=False, is_color=True)\n",
    "    A_recons_list.append(img_dict)\n",
    "    A_recons_list.append(img_recons)\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #main()\n",
    "    print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/piccaso/0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b994cafbf58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mA_recons_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtraining_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_iter_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     reconstructor = Image_Reconstructor(path=path_dict_img,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                         \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                         \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-eb8f5c7ce954>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, n_components, iterations, sub_iterations, num_patches, batch_size, downscale_factor, patch_size, patches_file, patches, is_matrix, is_stack, is_color)\u001b[0m\n\u001b[1;32m     56\u001b[0m         '''\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# read in image as array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_img_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_img_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-eb8f5c7ce954>\u001b[0m in \u001b[0;36mread_img_as_array\u001b[0;34m(self, path, is_matrix, is_color)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# it was +-1 matrix; now it is 0-1 matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_color\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/colourgraphenv/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/piccaso/0.jpg'"
     ]
    }
   ],
   "source": [
    "patch_size = 5\n",
    "#sources = [\"Data/renoir/\" + str(n) + \".jpg\" for n in np.arange(0,1)]\n",
    "path_dict_img = \"Data/piccaso/0.jpg\"\n",
    "path_recons = \"Data/renoir/0.jpg\"\n",
    "training_iter_list = [0]\n",
    "W_list = []\n",
    "A_recons_list = []\n",
    "for training_iter in training_iter_list:\n",
    "    reconstructor = Image_Reconstructor(path=path_dict_img,\n",
    "                                        n_components=25,\n",
    "                                        iterations=training_iter,\n",
    "                                        sub_iterations=10,\n",
    "                                        patch_size=patch_size,\n",
    "                                        batch_size=10,\n",
    "                                        num_patches=10,\n",
    "                                        downscale_factor=4,\n",
    "                                        is_matrix=False,\n",
    "                                        is_color=True)\n",
    "    # reconstructor.save_patches(\"escher_patches.npy\")\n",
    "    reconstructor.train_dict()\n",
    "    # reconstructor.W = np.load('Image_dictionary/dict_learned_21.npy')\n",
    "    W_list.append(reconstructor.W)  # trained dictionary\n",
    "    #reconstructor.display_dictionary(img_dict)\n",
    "    reconstructor.reconstruct_image_color(path=path_recons,\n",
    "                                          recons_resolution=4)\n",
    "    A_recons_list.append(reconstructor.A_recons)\n",
    "\n",
    "### Append original images for dictionary learning and reconstruction \n",
    "img_dict = reconstructor.read_img_as_array(path_dict_img, is_matrix=False, is_color=True)\n",
    "img_recons = reconstructor.read_img_as_array(path_recons, is_matrix=False, is_color=True)\n",
    "A_recons_list.append(img_dict)\n",
    "A_recons_list.append(img_recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recons_dict_list(W_list=W_list, \n",
    "                         training_iter_list=training_iter_list,\n",
    "                         A_recons_list=A_recons_list,\n",
    "                         fig_size = [11,6],\n",
    "                         save_path = 'image_dictionary/dict_recons_list_0',\n",
    "                         title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 30\n",
    "#sources = [\"Data/renoir/\" + str(n) + \".jpg\" for n in np.arange(0,1)]\n",
    "path_dict_img = \"Data/piccaso/0.jpg\"\n",
    "path_recons = \"Data/renoir/0.jpg\"\n",
    "training_iter_list = [0,2,100]\n",
    "W_list = []\n",
    "A_recons_list = []\n",
    "for training_iter in training_iter_list:\n",
    "    reconstructor = Image_Reconstructor(path=path_dict_img,\n",
    "                                        n_components=25,\n",
    "                                        iterations=training_iter,\n",
    "                                        sub_iterations=10,\n",
    "                                        patch_size=patch_size,\n",
    "                                        batch_size=10,\n",
    "                                        num_patches=10,\n",
    "                                        downscale_factor=10,\n",
    "                                        is_matrix=False,\n",
    "                                        is_color=True)\n",
    "    # reconstructor.save_patches(\"escher_patches.npy\")\n",
    "    reconstructor.train_dict()\n",
    "    # reconstructor.W = np.load('Image_dictionary/dict_learned_21.npy')\n",
    "    W_list.append(reconstructor.W)  # trained dictionary\n",
    "    #reconstructor.display_dictionary(img_dict)\n",
    "    reconstructor.reconstruct_image_color(path=path_recons,\n",
    "                                          recons_resolution=10)\n",
    "    A_recons_list.append(reconstructor.A_recons)\n",
    "\n",
    "### Append original images for dictionary learning and reconstruction \n",
    "img_dict = reconstructor.read_img_as_array(path_dict_img, is_matrix=False, is_color=True)\n",
    "img_recons = reconstructor.read_img_as_array(path_recons, is_matrix=False, is_color=True)\n",
    "A_recons_list.append(img_dict)\n",
    "A_recons_list.append(img_recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recons_dict_list(W_list=W_list, \n",
    "                         training_iter_list=training_iter_list,\n",
    "                         A_recons_list=A_recons_list,\n",
    "                         fig_size = [11,6],\n",
    "                         save_path = 'image_dictionary/dict_recons_list_0',\n",
    "                         title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recons_dict_list(W_list=W_list, \n",
    "                         training_iter_list=training_iter_list,\n",
    "                         A_recons_list=A_recons_list,\n",
    "                         fig_size = [11,6],\n",
    "                         save_path = 'image_dictionary/dict_recons_list_0',\n",
    "                         title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recons_dict_list(W_list=W_list, \n",
    "                         training_iter_list=training_iter_list,\n",
    "                         A_recons_list=A_recons_list,\n",
    "                         fig_size = [11,6],\n",
    "                         save_path = 'image_dictionary/dict_recons_list_1',\n",
    "                         title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
